import pandas as pd 
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold 
from sklearn.preprocessing import StandardScaler 
from sklearn.experimental import enable_iterative_imputer 
from sklearn.impute import IterativeImputer 
from sklearn.svm import SVC 
from sklearn.calibration import CalibratedClassifierCV 
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, make_scorer, f1_score 
from sklearn.compose import ColumnTransformer 
from sklearn.pipeline import Pipeline 
from sklearn.base import TransformerMixin 

  

# Load the continuous and discrete datasets 
file_path = 'Filtered_Endometriosis_Split4.xlsx' 
continuous_data = pd.read_excel(file_path, sheet_name="Continuous") 
discrete_data = pd.read_excel(file_path, sheet_name="Discrete") 

  

# Ensure that the target columns are the same in both datasets 
y_cont = continuous_data['Endometriosis_Status'] 
y_disc = discrete_data['Endometriosis_Status'] 
assert (y_cont == y_disc).all(), "Target columns do not match between continuous and discrete data." 

  

# Define features and target 
X_cont = continuous_data.drop(columns=['Endometriosis_Status'])  
X_disc = discrete_data.drop(columns=['Endometriosis_Status'])    
X = pd.concat([X_cont, X_disc], axis=1)  
y = y_cont  

  

# Split the data into training and testing sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) 

  

# Custom transformer to convert numpy array back to DataFrame after imputation 
class DataFrameConverter(TransformerMixin): 
    def __init__(self, columns): 
        self.columns = columns 
         

    def fit(self, X, y=None): 
        return self 
     

    def transform(self, X): 
        return pd.DataFrame(X, columns=self.columns) 
  

# Define column transformer to scale only continuous variables and pass through discrete ones 
preprocessor = ColumnTransformer( 
    transformers=[ 
        ('scaler', StandardScaler(), X_cont.columns),  
    ], 
    remainder='passthrough'  
) 

  

# Create a pipeline with imputation, scaling, conversion, and SVM classifier 
pipeline = Pipeline(steps=[ 
    ('imputer', IterativeImputer(max_iter=50, random_state=0)),   
    ('converter', DataFrameConverter(columns=X.columns)),         
    ('preprocessor', preprocessor),  
    ('classifier', SVC(probability=True, class_weight='balanced', random_state=42))   
]) 

  

# Define AUC as the scoring metric 
auc_scorer = make_scorer(roc_auc_score) 

  

# Define the parameter grid for GridSearchCV 
param_grid = { 
    'classifier__C': [1, 10, 100], 
    'classifier__gamma': ['scale', 'auto'], 
    'classifier__kernel': ['linear', 'rbf', 'poly'], 
    'classifier__degree': [2, 3, 4] 
} 

  

# Use stratified cross-validation 
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) 

  

# GridSearchCV with pipeline 
grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=auc_scorer, n_jobs=-1) 
grid_search.fit(X_train, y_train) 

  

# Calibrate the best model from GridSearchCV 
calibrated_svm = CalibratedClassifierCV(grid_search.best_estimator_, method='sigmoid', cv=cv) 
calibrated_svm.fit(X_train, y_train) 

  

# Make predictions on the test set 
y_pred_prob = calibrated_svm.predict_proba(X_test)[:, 1] 
y_pred = calibrated_svm.predict(X_test) 

  

# Evaluate the model performance on the test set 
roc_auc = roc_auc_score(y_test, y_pred_prob) 
conf_matrix = confusion_matrix(y_test, y_pred) 
tn, fp, fn, tp = conf_matrix.ravel() 
specificity = tn / (tn + fp) 
sensitivity = tp / (tp + fn) 
accuracy = accuracy_score(y_test, y_pred) 
precision = precision_score(y_test, y_pred) 
recall = recall_score(y_test, y_pred) 
f1 = f1_score(y_test, y_pred) 

  

# Display results 
print(f"Best parameters found: {grid_search.best_params_}") 
print(f"Accuracy: {accuracy:.4f}") 
print(f"Precision: {precision:.4f}") 
print(f"Specificity: {specificity:.4f}") 
print(f"Recall: {recall:.4f}") 
print(f"ROC AUC: {roc_auc:.4f}") 
print(f"F1 Score: {f1:.4f}") 
print(f"\nClassification Report:\n{classification_report(y_test, y_pred)}") 
